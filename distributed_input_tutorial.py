# -*- coding: utf-8 -*-
"""Distributed_input_tutorial.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tlkZ7H8icUu8VnUPzpKfCs4r3zPo470T

with th.distribute, it is wasy to scale training from single to multiple machines. In order to do so, users have to distribute the input across the machines, for which tf. distribute provides automatic distribution.

here, different ways to create distributed datasets and iterators using tf.distribute will be shown.

#Distributed Datasets
to use tf.distribute, use tf.data.Dataset to represent the input. In a non-distributed instance, first create a tf.data.Dataset, then iterate over the elements:
"""

import tensorflow as tf

# Helper libraries
import numpy as np
import os

print(tf.__version__)

# Simulate multiple CPUs with virtual devices
N_VIRTUAL_DEVICES = 2
physical_devices = tf.config.list_physical_devices("CPU")
tf.config.set_logical_device_configuration(
    physical_devices[0], [tf.config.LogicalDeviceConfiguration() for _ in range(N_VIRTUAL_DEVICES)])

print("Available devices:")
for i, device in enumerate(tf.config.list_logical_devices()):
  print("%d) %s" % (i, device))

global_batch_size = 16
# Create a tf.data.Dataset object.
dataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(100).batch(global_batch_size)

@tf.function
def train_step(inputs):
  features, labels = inputs
  return labels - 0.3 * features

# Iterate over the dataset using the for..in construct.
for inputs in dataset:
  print(train_step(inputs))

"""## tf.distribute.Strategy.experimental_distribute_dataset
###Usage
this api takes s tf.data.Dataset as input and returns a tf.distribute.DistributedDataset. The input should be batched witch the global batch size. One can iterate over this dataset using an iter(ator).  Recommended if there are no specific ways in which the input should be sharded.
"""

global_batch_size = 16
mirrored_strategy = tf.distribute.MirroredStrategy()

dataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(100).batch(global_batch_size)
# Distribute input using the `experimental_distribute_dataset`.
dist_dataset = mirrored_strategy.experimental_distribute_dataset(dataset)
# 1 global batch of data fed to the model in 1 step.
print(next(iter(dist_dataset)))

"""##Properties
###Batching
tf.distribute rebatches the input with a new batch size equal to global batch size divided by num of replicas. when the user calls next in the distributed iterator, a per replica batch size of data is returned on each replica. The rebatched dataset will be a multiple of num of replicas.

###Sharding
tf.distribute autoshards the input dataset with MultiWorkerMirroredSTrategy and TPUSAtrategy. There is NO autosharding when training with ParameterServerStrategy.
"""

dataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(64).batch(16)
options = tf.data.Options()
options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA
dataset = dataset.with_options(options)

"""Adaptions to autosharding via  tf.data.experimental.AutoShardPolicy:
*  AUTO: default option. it attemps to shard by file. If no file-based dataset is found,  it will fail and tf.distribute will fall back to sharding by DATA. If the input dataset if file-bsed and the num of files is less than um of workers, an error will be raised. In that case, explicitly set policy to AutoShardPolicy.DATA or split source to smaller files.
*  FILE: If sharding of files over workers is desired. use this if num of files is larger than num of workers and data distriobution in files is evenly. in other case there might be idle workers.
*  DATA: Will autoshard the elements over workers. each worker reads entire dataset and only process its assigned shard.
*  OFF: Turns off autosharding

###Prefetching:
tf.distribute adds a prefetch tgransformation by default. Argument buffer_size is equal to num of replicas in synch

#tf.distribute.Strategy.distribute_datasets_from_function
### Usage
takes input fcn and returns tf.distribute.DistributedDataset. Input fcn has a tf.distribute.InputContext arg and should return a tf.data.Dataset. The user has to batch and shard the dataset manually, but has better scalability and performance!
"""

mirrored_strategy = tf.distribute.MirroredStrategy()

def dataset_fn(input_context):
  batch_size = input_context.get_per_replica_batch_size(global_batch_size)
  dataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(64).batch(16)
  dataset = dataset.shard(
      input_context.num_input_pipelines, input_context.input_pipeline_id)
  dataset = dataset.batch(batch_size)
  dataset = dataset.prefetch(2)  # This prefetches 2 batches per device.
  return dataset

dist_dataset = mirrored_strategy.distribute_datasets_from_function(dataset_fn)

"""##Properties
###Batching
the return value of the input fcn should be batched with the per replica batch size

###Sharding
the td.distribute.InputContect, which is passed to the users input fcn has information abiout num of workers, worker ids, etc...  It can handle sharding set as part of InputContext

###Prefetching 
User has to manually call Dataset.prefetch in order to add prefetchinfg

#Distributed iterators
the user has to create an iterator on tf.distribute.DistributedDataset to iterate over it and access its elements:
##Usages
###Pythonic for loop
Can be done by a for loop. The returned elements from tf.distribute.DistributedIterator can be a Tensor or a tf.distribute.DistributedValues obj. Placing the loop in a tf.function will give performance boost. Note: break and return are currently not supported in that case!
"""

global_batch_size = 16
mirrored_strategy = tf.distribute.MirroredStrategy()

dataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(100).batch(global_batch_size)
dist_dataset = mirrored_strategy.experimental_distribute_dataset(dataset)

@tf.function
def train_step(inputs):
  features, labels = inputs
  return labels - 0.3 * features

for x in dist_dataset:
  # train_step trains the model using the dataset elements
  loss = mirrored_strategy.run(train_step, args=(x,))
  print("Loss is ", loss)

"""###Use iter to create explicit iterator
to iterate over tf.distribute.DistributedDataset the user can create a tf.distribute.DistributedIterator using iter. With explicit iterator, one can iterate over a fixed num of steps. To get the next el from an tf.distribute.DistributedIterator, call next(dist_iterator), dist_iterator.get_next(), or dist_iterator.get_next_as_optional().
"""

num_epochs = 10
steps_per_epoch = 5
for epoch in range(num_epochs):
  dist_iterator = iter(dist_dataset)
  for step in range(steps_per_epoch):
    # train_step trains the model using the dataset elements
    loss = mirrored_strategy.run(train_step, args=(next(dist_iterator),))
    # which is the same as
    # loss = mirrored_strategy.run(train_step, args=(dist_iterator.get_next(),))
    print("Loss is ", loss)

"""With next or tf.distribute.DistributedIterator.get_next, the DistributedIterator will raise an error if it has reached its end. In python, that error can be catched, if host training loop is used, this will not work."""

@tf.function
def train_fn(iterator):
  for _ in tf.range(steps_per_loop):
    strategy.run(step_fn, args=(next(iterator),))

"""Here, train_fc wraps the step body in a tf.range. Here, different iterations with no dependency could start in parallel. This can lead to outofrange errors in later iterations before earlier ones are finished. in this case all ops will terminate immediately. To avoid this, use  tf.distribute.DistributedIterator.get_next_as_optional."""

# You can break the loop with `get_next_as_optional` by checking if the `Optional` contains a value
global_batch_size = 4
steps_per_loop = 5
strategy = tf.distribute.MirroredStrategy()

dataset = tf.data.Dataset.range(9).batch(global_batch_size)
distributed_iterator = iter(strategy.experimental_distribute_dataset(dataset))

@tf.function
def train_fn(distributed_iterator):
  for _ in tf.range(steps_per_loop):
    optional_data = distributed_iterator.get_next_as_optional()
    if not optional_data.has_value():
      break
    per_replica_results = strategy.run(lambda x: x, args=(optional_data.get_value(),))
    tf.print(strategy.experimental_local_results(per_replica_results))
train_fn(distributed_iterator)

"""# Using element_spec
when elements of a distributed ds are distributed to tf.function and want a tf.TypeSpec guarantee, specify input_signature arg.
 To get the tf.TypeSpec corresponding to this distributed value, you can use tf.distribute.DistributedDataset.element_spec or tf.distribute.DistributedIterator.element_spec.
"""

global_batch_size = 16
epochs = 5
steps_per_epoch = 5
mirrored_strategy = tf.distribute.MirroredStrategy()

dataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(100).batch(global_batch_size)
dist_dataset = mirrored_strategy.experimental_distribute_dataset(dataset)

@tf.function(input_signature=[dist_dataset.element_spec])
def train_step(per_replica_inputs):
  def step_fn(inputs):
    return 2 * inputs

  return mirrored_strategy.run(step_fn, args=(per_replica_inputs,))

for _ in range(epochs):
  iterator = iter(dist_dataset)
  for _ in range(steps_per_epoch):
    output = train_step(next(iterator))
    tf.print(output)

"""# Data preprocessing
There are two easy ways for preprocesing
* Keras preprocessing layers: keras-native preprocessing pipelines. When distributing stateful preprocessing layers, they should be replicated to all workers. To use: make them part of model or apply to datasets
* tf.Transform: allows definition of instance-level and full-pass data transformation trhrough processing pipelines. It has two phases: analysis and transform phase

##Keras preprocessing vs tf.Transform
tf.Transform can work with any datasizes, so if working with large datasets, this should be used. keras works better in a keras model env.


"""